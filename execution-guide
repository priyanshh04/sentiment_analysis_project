# Sentiment Analysis Project - Execution Guide

## Overview
This document provides step-by-step instructions for executing the Amazon Musical Instruments Reviews sentiment analysis project.

## Project Structure Summary

The complete sentiment analysis project has been created with the following components:

### Core Files
1. **main.py** - Main execution script that runs the complete pipeline
2. **configs/config.py** - Centralized configuration management
3. **README.md** - Comprehensive project documentation

### Source Code Modules
- **src/utils/data_loader.py** - Data loading and validation utilities
- **src/preprocessing/feature_engineering.py** - Feature creation and engineering
- **src/preprocessing/text_preprocessing.py** - Advanced text cleaning and processing
- **src/models/sentiment_models.py** - Machine learning model implementations
- **src/evaluation/model_evaluation.py** - Model evaluation and visualization

### Interactive Analysis
- **notebooks/sentiment_analysis_exploration.ipynb** - Jupyter notebook for interactive exploration

### Configuration & Dependencies
- **requirements/requirements.txt** - All Python package dependencies
- **tests/test_pipeline.py** - Unit tests for pipeline validation

## Step-by-Step Execution Guide

### 1. Environment Setup
```bash
# Navigate to project directory
cd sentiment_analysis_project

# Create virtual environment (recommended)
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements/requirements.txt
```

### 2. Data Preparation
- Ensure `Instruments_Reviews.csv` is placed in `data/raw/` directory
- The dataset should contain the original 9 columns as analyzed earlier

### 3. Run Complete Pipeline
```bash
# Execute the complete sentiment analysis pipeline
python main.py
```

This will automatically:
- Load and validate the dataset
- Apply feature engineering (create 12 new features)
- Preprocess text data (cleaning, tokenization, lemmatization)
- Train 5 machine learning models
- Handle class imbalance with SMOTE
- Evaluate and compare all models
- Generate visualizations and reports
- Save trained models and results

### 4. Expected Outputs

After execution, you'll find:

#### Data Files
- `data/processed/processed_instruments_reviews.csv` - Dataset with engineered features
- `data/models/` - Trained model files (.joblib format)
- `data/models/best_model.joblib` - Best performing model

#### Reports & Analysis
- `reports/training_results.json` - Detailed training metrics
- `reports/evaluation_report.txt` - Comprehensive evaluation report
- `sentiment_analysis.log` - Complete execution log

#### Visualizations
- `plots/confusion_matrix_*.png` - Confusion matrices for each model
- `plots/roc_curves_comparison.png` - ROC curve comparisons
- `plots/metrics_comparison.png` - Model performance comparison
- `plots/class_distributions_*.png` - Class distribution analysis

### 5. Interactive Exploration
```bash
# Start Jupyter notebook
jupyter notebook

# Open and run: notebooks/sentiment_analysis_exploration.ipynb
```

## Key Features Implemented

### 1. Comprehensive Feature Engineering
- **Target Variables**: Binary and 3-class sentiment labels from ratings
- **Helpfulness Features**: Extracted from user vote data
- **Text Metrics**: Length, word count, sentence analysis
- **Temporal Features**: Year, month, seasonal patterns
- **Sentiment Indicators**: Punctuation analysis, emotion markers

### 2. Advanced Text Preprocessing
- Lowercase conversion and whitespace normalization
- URL, email, and HTML tag removal
- Punctuation and digit handling
- Contraction expansion
- Stop word removal with domain-specific words
- Lemmatization with POS tagging
- Configurable preprocessing pipeline

### 3. Machine Learning Models
- **Logistic Regression**: Fast, interpretable baseline
- **Support Vector Machine**: High-dimensional text classification
- **Random Forest**: Ensemble method for robustness
- **Naive Bayes**: Traditional text classification approach
- **XGBoost**: Advanced gradient boosting (optional)

### 4. Class Imbalance Solutions
- SMOTE (Synthetic Minority Oversampling Technique)
- Class weight balancing in algorithms
- Stratified sampling for train/test splits
- Focus on minority class performance metrics

### 5. Comprehensive Evaluation
- Multiple metrics: Accuracy, Precision, Recall, F1-Score, ROC-AUC
- Confusion matrices and classification reports
- Cross-validation with stratified k-folds
- Comparative analysis with visualizations
- Business-focused performance reporting

## Expected Performance

Based on the dataset characteristics and implemented techniques:

- **Overall Accuracy**: 85-90%
- **F1-Score**: 0.75-0.85
- **Best Performing Model**: Typically Logistic Regression or SVM
- **Training Time**: 5-15 minutes on standard hardware
- **Memory Usage**: ~500MB-1GB depending on feature extraction

## Troubleshooting Common Issues

### 1. Import Errors
- Ensure all dependencies are installed: `pip install -r requirements/requirements.txt`
- Check Python path includes the src directory
- Verify all __init__.py files are present

### 2. NLTK Data Issues
```python
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')
```

### 3. Memory Issues
- Reduce TF-IDF max_features in config.py
- Use smaller sample size for initial testing
- Increase system virtual memory

### 4. Dataset Issues
- Verify CSV file format and encoding
- Check column names match expected format
- Ensure no critical columns are missing

## Customization Options

### Configuration Parameters
Edit `configs/config.py` to modify:
- Text preprocessing settings
- Model hyperparameters
- Feature extraction parameters
- Evaluation metrics

### Model Selection
Modify the models_to_train list in `SentimentModelTrainer` to include/exclude specific algorithms.

### Feature Engineering
Add custom features by extending the `FeatureEngineer` class methods.

## Production Deployment

### Model Usage
```python
# Load trained model
import joblib
model = joblib.load('data/models/best_model.joblib')

# Make predictions
predictions = model['model'].predict(new_texts)
```

### API Deployment
The trained models can be deployed using Flask/FastAPI by:
1. Loading the best model
2. Creating prediction endpoints
3. Implementing the preprocessing pipeline
4. Adding input validation and error handling

## Business Applications

### Immediate Use Cases
- Automated review sentiment monitoring
- Product quality assessment
- Customer satisfaction tracking
- Competitive analysis

### Strategic Applications
- Product development insights
- Marketing campaign optimization
- Customer service prioritization
- Brand reputation management

## Validation and Testing

### Unit Tests
```bash
# Run all tests
python -m pytest tests/ -v

# Run specific test
python -m pytest tests/test_pipeline.py -v
```

### Model Validation
- Cross-validation scores
- Hold-out test set evaluation
- Confusion matrix analysis
- ROC/PR curve assessment

## Support and Maintenance

### Regular Updates
- Retrain models with new data quarterly
- Monitor model performance drift
- Update preprocessing rules as needed
- Refresh feature engineering based on insights

### Performance Monitoring
- Track prediction accuracy on new data
- Monitor class distribution changes
- Assess feature importance evolution
- Update evaluation metrics as needed

## Conclusion

This sentiment analysis project provides a complete, production-ready solution for analyzing Amazon musical instrument reviews. The modular architecture allows for easy customization and extension, while the comprehensive evaluation ensures reliable performance assessment.

The implementation successfully addresses the key challenges of:
- Severe class imbalance in the dataset
- Text preprocessing for domain-specific content
- Feature engineering for enhanced model performance
- Comprehensive evaluation and comparison of multiple algorithms

Execute the pipeline using `python main.py` and explore the results through the generated reports and visualizations.